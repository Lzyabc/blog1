# 二、操作系统
## 1. 进程与线程 
进程是资源分配的基本单位。
进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程

### 1.1 进程与线程的区别
- 线程是独立调度的基本单位。
- 一个进程中可以有多个线程，它们共享进程资源。
（1）资源分配方式不同：进程有独立的地址空间，线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间；
（2）健壮性不同：一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮;
（3）切换开销不同：进程切换时，耗费资源较大，效率要差一些
（4）资源共享方式不同：线程可以通过全局变量等方式共享数据，进程无法直接访问对方地址空间中的数据。

例：QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。  
[进程和线程的区别？](https://blog.csdn.net/mxsgoden/article/details/8821936)

- **线程里面有什么是独立的**  
    栈：是个线程独有的，保存其运行状态和局部自动变量的。栈是　thread safe的，操作系统在切换线程的时候会自动的切换栈，就是切换　ＳＳ／ＥＳＰ寄存器。  
    线程独享资源:程序计数器,寄存器,栈,状态字.

### 1.2 并发与并行的区别  
并发是指多个任务在同一时间段同时执行；并行是多个任务在同一时间点同时执行。

## 2. 进程
### 2.1 现代操作系统的进程内存分布
一个linux进程分为几个部分:  （自低地址向高地址）
1. text段，代码段，可读可执行不可写，。  
2. data段，数据段，存放已初始化的全局变量和已初始化的static变量  
3. bss段,存放全局未初始化变量和未初始化的static变量  
以上这3部分大小是静态的。  
4. heap,堆在进程空间中是自低地址向高地址增长。  
5. stack,栈保存函数的局部变量，自高地址向低地址增长的。  
6. 再往上，也就是一个进程地址空间的顶部，存放了命令行参数和环境变量。  

[Hello World程序在Linux下的诞生与消亡](https://github.com/justtreee/blog/issues/4)  
### 2.2 进程调度算法
#### 先来先服务调度算法
#### 短作业(进程)优先调度算法
#### 优先权调度算法的类型
1. 非抢占式优先权算法
- 只有当进程完成执行或主动放弃时系统才可再将资源分配给另一进程。主要用于批处理系统或某些对实时性要求不严的系统中。

2. 抢占式优先权调度算法
- 即使进程正在执行，系统也可以强行终止当前进程，将资源分配给另一个进程。主要用于要求较严格的实时系统，以及对性能要求较高的批处理和分时系统中。

#### 时间片轮转法
在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾，重复上述过程。
### 2.3 Linux进程的状态转换图*

![1](http://hi.csdn.net/attachment/201203/13/0_1331619249llz4.gif)
    
- 运行状态（TASK_RUNNING）

    当进程正在被CPU执行，或已经准备就绪随时可由调度程序执行，则称该进程为处于运行状态（running）。进程可以在内核态运行，也可以在用户态运行。当系统资源已经可用时，进程就被唤醒而进入准备运行状态，该状态称为就绪态。这些状态（图中中间一列）在内核中表示方法相同，都被成为处于TASK_RUNNING状态。
- 可中断睡眠状态（TASK_INTERRUPTIBLE）

    当进程处于可中断等待状态时，系统不会调度该进程执行。当系统产生一个中断或者释放了进程正在等待的资源，或者进程收到一个信号，都可以唤醒进程转换到就绪状态（运行状态）。
- 不可中断睡眠状态（TASK_UNINTERRUPTIBLE）

    与可中断睡眠状态类似。但处于该状态的进程只有被使用wake_up()函数明确唤醒时才能转换到可运行的就绪状态。
- 暂停状态（TASK_STOPPED）

    当进程收到信号SIGSTOP、SIGTSTP、SIGTTIN或SIGTTOU时就会进入暂停状态。可向其发送SIGCONT信号让进程转换到可运行状态。在Linux 0.11中，还未实现对该状态的转换处理。处于该状态的进程将被作为进程终止来处理。
- 僵死状态（TASK_ZOMBIE）

    当进程已停止运行，但其父进程还没有询问其状态时，则称该进程处于僵死状态。
    当一个进程的运行时间片用完，系统就会使用调度程序强制切换到其它的进程去执行。另外，如果进程在内核态执行时需要等待系统的某个资源，此时该进程就会调用sleep_on()或sleep_on_interruptible()自愿地放弃CPU的使用权，而让调度程序去执行其它进程。进程则进入睡眠状态（TASK_UNINTERRUPTIBLE或TASK_INTERRUPTIBLE）。
    只有当进程从“内核运行态”转移到“睡眠状态”时，内核才会进行进程切换操作。在内核态下运行的进程不能被其它进程抢占，而且一个进程不能改变另一个进程的状态。为了避免进程切换时造成内核数据错误，内核在执行临界区代码时会禁止一切中断。
### 2.4 孤儿进程，僵尸进程
- 孤儿进程  

    一个父进程退出，而它的一个或多个子进程还在运行，这些子进程称为孤儿进程。孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作，所以孤儿进程不会对系统造成危害。

- 僵死进程

    一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait 或 waitpid 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait 或 waitpid，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵死进程。

    通过 ps 命令显示出来的状态为 Z。

    系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。

    要消灭系统中大量的僵死进程，只需要将其父进程杀死，此时所有的僵死进程就会变成孤儿进程被 init 所收养， init 会释放僵死进程所占有的资源。
--------
### 2.5 进程间通信方式*
- 同一主机上的进程通信方式
   * UNIX进程间通信方式: 包括管道(PIPE), 有名管道(FIFO), 和信号(Signal)
   * System V进程通信方式：包括信号量(Semaphore), 消息队列(Message Queue), 和共享内存(Shared Memory)
	- 网络主机间的进程通信方式
   * RPC: Remote Procedure Call 远程过程调用
   * Socket: 当前最流行的网络通信方式, 基于TCP/IP协议的通信方式.
- 各自的特点如下:  
	- 管道(PIPE)：管道是一种半双工的通信方式，数据只能单向流动，而且只能在 **具有亲缘关系(父子进程)的进程间使用** 。另外管道传送的是无格式的字节流，并且管道缓冲区的大小是有限的（管道缓冲区存在于内存中，在管道创建时，为缓冲区分配一个页面大小）。
	- 有名管道 (FIFO)： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
	- 信号(Signal)： 信号用于通知接收进程某个事件已经发生。
	- 信号量(Semaphore)：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
	- 消息队列(Message Queue)：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
	- 共享内存(Shared Memory )：共享内存就是映射一段由一个进程创建能被其他进程所访问的内存。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
	- 套接字(Socket)： 可用于不同主机间的进程通信。

[Linux进程间通信的几种方式总结](https://blog.csdn.net/gatieme/article/details/50908749)


#### 2.4.1 信号量、互斥体和自旋锁
**1. 信号量**

信号量又称为信号灯，它是用来协调不同进程间的数据对象的，而最主要的应用是共享内存方式的进程间通信。本质上，信号量是一个计数器，它用来记录对某个资源（如共享内存）的存取状况。一般说来，为了获得共享资源，进程需要执行下列操作： 
1. 测试控制该资源的信号量。 
2. 若此信号量的值为正，则允许进行使用该资源。进程将信号量减1。 
3. 若此信号量为0，则该资源目前不可用，进程进入睡眠状态，直至信号量值大于0，进程被唤醒，转入步骤（1）。 
4. 当进程不再使用一个信号量控制的资源时，信号量值加1。如果此时有进程正在睡眠等待此信号量，则唤醒此进程。

维护信号量状态的是Linux内核操作系统而不是用户进程。我们可以从头文件/usr/src/linux/include/linux/sem.h 中看到内核用来维护信号量状态的各个结构的定义。信号量是一个数据集合，用户可以单独使用这一集合的每个元素。要调用的第一个函数是semget，用以获得一个信号量ID。

**2. 互斥锁**

在任意时刻至多有一个线程获取锁。假如锁已被占用，其他要获取锁的线程会被挂起。好处是不占CPU等计算资源，缺点是带来线程挂起和启动开销。

**3. 自旋锁**
自旋锁不会引起调用者睡眠，而是会循环查询锁是否被释放。


自旋锁比较适用于锁使用者保持锁时间比较短的情况。  [*]
正是由于自旋锁使用者一般保持锁时间非常短，因此选择自旋而不是睡眠是非常必要的，自旋锁的效率远高于互斥锁。信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因此只能在进程上下文使用， **而自旋锁适合于保持时间非常短的情况，它可以在任何上下文使用** 。如果被保护的共享资源只在进程上下文访问，使用信号量保护该共享资源非常合适，如果对共享资源的访问时间非常短，自旋锁也可以。但是如果被保护的共享资源需要在中断上下文访问（包括底半部即中断处理句柄和顶半部即软中断），就必须使用自旋锁。自旋锁保持期间是抢占失效的，而信号量和读写信号量保持期间是可以被抢占的。自旋锁只有在内核可抢占或SMP（多处理器）的情况下才真正需要，在单CPU且不可抢占的内核下，自旋锁的所有操作都是空操作。另外格外注意一点：自旋锁不能递归使用。


**4. 信号量/互斥体和自旋锁的区别** [*]

信号量/互斥体允许进程睡眠属于睡眠锁，自旋锁则不允许调用者睡眠，而是让其循环等待，所以有以下区别应用 
1. 信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因而自旋锁适合于保持时间非常短的情况
2. 自旋锁可以用于中断，不能用于进程上下文(会引起死锁)。而信号量不允许使用在中断中，而可以用于进程上下文
3. 自旋锁保持期间是抢占失效的，自旋锁被持有时，内核不能被抢占，而信号量和读写信号量保持期间是可以被抢占的
   
另外需要注意的是

1. 信号量锁保护的临界区可包含可能引起阻塞的代码，而自旋锁则绝对要避免用来保护包含这样代码的临界区，因为阻塞意味着要进行进程的切换，如果进程被切换出去后，另一进程企图获取本自旋锁，死锁就会发生。
2. 在你占用信号量的同时不能占用自旋锁，因为在你等待信号量时可能会睡眠，而在持有自旋锁时是不允许睡眠的。

 

**5. 信号量和互斥体之间的区别** [*]

- 概念上的区别：     
    - 信号量：是进程间（线程间）同步用的，一个进程（线程）完成了某一个动作就通过信号量告诉别的进程（线程），别的进程（线程）再进行某些动作。有二值和多值信号量之分。

    - 互斥锁：是线程间互斥用的，一个线程占用了某一个共享资源，那么别的线程就无法访问，直到这个线程离开，其他的线程才开始可以使用这个共享资源。可以把互斥锁看成二值信号量。  

- 上锁时：

    - 信号量: 只要信号量的value大于0，其他线程就可以sem_wait成功，成功后信号量的value减一。若value值不大于0，则sem_wait阻塞，直到sem_post释放后value值加一。一句话，信号量的value>=0。

    - 互斥锁: 只要被锁住，其他任何线程都不可以访问被保护的资源。如果没有锁，获得资源成功，否则进行阻塞等待资源可用。一句话，线程互斥锁的vlaue可以为负数。  

- 使用场所：

    - 信号量主要适用于进程间通信，当然，也可用于线程间通信。而互斥锁只能用于线程间通信。
### 2.6 进程间如何同步(Synchronization) [*]
- [进程的同步与通信，进程与线程同步的区别，进程与线程通信的区别](http://www.cnblogs.com/youngforever/p/3250270.html)
- 进程的互斥、同步、通信都是基于这两种基本关系而存在的，为了解决进程间竞争关系（间接制约关系）而引入进程互斥；为了解决进程间松散的协作关系( 直接制约关系)而引入进程同步；为了解决进程间紧密的协作关系而引入进程通信。
- 某些进程为完成同一任务需要分工协作，由于合作的每一个进程都是独立地以不可预知的速度推进，这就需要相互协作的进程在某些协调点上协 调各自的工作。当合作进程中的一个到达协调点后，在尚未得到其伙伴进程发来的消息或信号之前应阻塞自己，直到其他合作进程发来协调信号或消息后方被唤醒并继续执行。这种协作进程之间相互等待对方消息或信号的协调关系称为**进程同步**。
- 进程的同步（Synchronization）是解决进程间协作关系( 直接制约关系) 的手段。进程同步指两个以上进程基于某个条件来协调它们的活动。一个进程的执行依赖于另一
个协作进程的消息或信号，当一个进程没有得到来自于另一个进程的消息或信号时则需等待，直到消息或信号到达才被唤醒。

- 不难看出，进程互斥关系是一种特殊的进程同步关系，即逐次使用互斥共享资源，也是对进程使用资源次序上的一种协调。

- **进程同步的方法**
	- **Linux下**
		- Linux 下常见的**进程同步方法**有：SysVIPC 的 sem（信号量）、file locking / record locking（通过 fcntl 设定的文件锁、记录锁）、futex（基于共享内存的快速用户态互斥锁）。针对线程（pthread）的还有 pthread_mutex 和 pthread_cond（条件变量）。
		- Linux 下常见的**进程通信的方法**有 ：pipe（管道），FIFO（命名管道），socket（套接字），SysVIPC 的 shm（共享内存）、msg queue（消息队列），mmap（文件映射）。以前还有 STREAM，不过现在比较少见了（好像）。

	- **Windows下**
		- 在Windwos中，进程同步主要有以下几种：互斥量、信号量、事件、可等计时器等几种技术。
		- 在Windows下，进程通信主要有以下几种：内存映射、管道、消息等，但是内存映射是最基础的，因为，其他的进程通信手段在内部都是考内存映射来完成的。
### 2.7 死锁

#### 死锁的四个必要条件
（1）互斥访问：资源只能被至多一个进程占有；

（2）请求和保持：占有资源的进程可以去请求新的资源，假如需要等待的时候，可以保存对原资源的占有；

（3）不可抢占：不可以抢占进程已占有资源，只能等待进程释放

（4）环路等待：存在一个进程--资源之间的环形链



#### 处理死锁的基本方法

预防死锁（破坏四个必要条件）：

- 资源一次性分配：（破坏请求和保持条件）

- 可剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

- 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）


#### 避免死锁（银行家算法）


在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。

#### 检测死锁

首先为每个进程和每个资源指定一个唯一的号码；

然后建立资源分配表和进程等待表，例如：

#### 解除死锁

当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：

剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；

撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。

## 3. 线程
### 3.1 线程间如何通讯
- 线程通信
	- 线程互斥
		互斥意味着“排它”，即两个线程不能同时进入被互斥保护的代码。Linux下可利用锁实现上述要求。
	- 线程同步
		同步就是线程等待某个事件的发生。只有当等待的事件发生线程才继续执行，否则线程挂起并放弃处理器。当多个线程协作时，相互作用的任务必须在一定的条件下同步。

- Linux系统中的线程间通信方式主要以下几种:
	*  锁机制：包括互斥锁、条件变量、读写锁  
   	互斥锁提供了以排他方式防止数据结构被并发修改的方法。
   读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
   条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
	*  信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
	*  信号机制(Signal)：类似进程间的信号处理

### 3.2 线程间同步
- 同步就是线程等待某个事件的发生。只有当等待的事件发生线程才继续执行，否则线程挂起并放弃处理器。当多个线程协作时，相互作用的任务必须在一定的条件下同步


### 3.3 是否需要线程安全
- [当我们在谈论XX是否线程安全时，我们在谈论什么？](https://www.zhihu.com/question/23244293)

### 3.4 线程间的同步和互斥是怎么做的
- Posix中两种线程同步机制，分别为互斥锁和信号量。这两个同步机制可以通过互相调用对方来实现，但互斥锁更适用于同时可用的资源是唯一的情况；信号量更适用于同时可用的资源为多个的情况。

### 3.5 ThreadLocal[*]
ThreadLocal 用于提供线程局部变量，在多线程环境可以保证各个线程里的变量独立于其它线程里的变量。也就是说 ThreadLocal 可以为每个线程创建一个【单独的变量副本】，相当于线程的 private static 类型变量。

对于 ThreadLocal 类型的变量，在一个线程中设置值，不影响其在其它线程中的值。也就是说 ThreadLocal 类型的变量的值在每个线程中是独立的。
- [Java 之 ThreadLocal 详解](https://juejin.im/post/5965ef1ff265da6c40737292)

#### 3.5.1 ThreadLocal 实现[*]
set(T value) 方法中，首先获取当前线程，然后在获取到当前线程的 ThreadLocalMap，如果 ThreadLocalMap 不为 null，则将 value 保存到 ThreadLocalMap 中，并用当前 ThreadLocal 作为 key；否则创建一个 ThreadLocalMap 并给到当前线程，然后保存 value。

ThreadLocalMap 相当于一个 HashMap，是真正保存值的地方。


同样的，在 get() 方法中也会获取到当前线程的 ThreadLocalMap，如果 ThreadLocalMap 不为 null，则把获取 key 为当前 ThreadLocal 的值；否则调用 setInitialValue() 方法返回初始值，并保存到新创建的 ThreadLocalMap 中。


事实上，从本质来讲，就是每个线程都维护了一个map，而这个map的key就是threadLocal，而值就是我们set的那个值，每次线程在get的时候，都从自己的变量中取值，既然从自己的变量中取值，那肯定就不存在线程安全问题，总体来讲，ThreadLocal这个变量的状态根本没有发生变化，他仅仅是充当一个key的角色，另外提供给每一个线程一个初始值。如果允许的话，我们自己就能实现一个这样的功能，只不过恰好JDK就已经帮我们做了这个事情。

## 5. 内存管理 段式页式
### 5.1 存储方式：页式段式

#### 1. 分页存储管理
用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。

系统将程序的逻辑空间按照同样大小也划分成若干页面，称为逻辑页面也称为页。程序的各个逻辑页面从0开始依次编号，称作逻辑页号或相对页号。每个页面内从0开始编址，称为页内地址。程序中的逻辑地址由两部分组成：页号P和页内位移量W。

分页系统中，允许将进程的每一页离散地存储在内存的任一物理块中，为了能在内存中找到每个页面对应的物理块，系统为每个进程建立一张页表，用于记录进程逻辑页面与内存物理页面之间的对应关系。页表的作用是实现从页号到物理块号的地址映射，地址空间有多少页，该页表里就登记多少行，且按逻辑页的顺序排列。

#### 2. 分段存储管理

作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。例程序段、数据段等。每个段都从0开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。整个作业的地址空间是二维的。

在段式虚拟存储系统中，虚拟地址由段号和段内地址组成，虚拟地址到实存地址的变换通过段表来实现。每个程序设置一个段表，段表的每一个表项对应一个段，每个表项至少包括三个字段：有效位（指明该段是否已经调入主存）、段起址(该段在实存中的首地址)和段长（记录该段的实际长度）。


- 分段存储方式的优点

    分页对程序员而言是不可见的，而分段通常对程序员而言是可见的，因而分段为组织程序和数据提供了方便。与页式虚拟存储器相比，段式虚拟存储器有许多优点：
    - 段的逻辑独立性使其易于编译、管理、修改和保护，也便于多道程序共享。

    - 段长可以根据需要动态改变，允许自由调度，以便有效利用主存空间。

    - 方便编程，分段共享，分段保护，动态链接，动态增长

- 因为段的长度不固定，段式虚拟存储器也有一些缺点：

    - 主存空间分配比较麻烦。

    - 容易在段间留下许多碎片，造成存储空间利用率降低。

    - 由于段长不一定是2的整数次幂，因而不能简单地像分页方式那样用虚拟地址和实存地址的最低若干二进制位作为段内地址，并与段号进行直接拼接，必须用加法操作通过段起址与段内地址的求和运算得到物理地址。因此，段式存储管理比页式存储管理方式需要更多的硬件支持。

#### 3. 段页式存储

段页式存储组织是分段式和分页式结合的存储组织方法，这样可充分利用分段管理和分页管理的优点。

1. 用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。

2.  用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。

**段页式存储管理的优缺点**

优点

1. 它提供了大量的虚拟存储空间。

1. 能有效地利用主存，为组织多道程序运行提供了方便。

缺点：

1. 增加了硬件成本、系统的复杂性和管理上的开消。

1. 存在着系统发生 **抖动** 的危险。

1. 存在着内碎片。

1. 还有各种表格要占用主存空间。

　段页式存储管理技术对当前的大、中型计算机系统来说，算是最通用、最灵活的一种方案。

**抖动**
由于虚拟存储器系统能从逻辑上扩大内存，人们希望在系统中能运行更多的进程，即增加多道程序度，以提高处理机的利用率。

如果多道程度过高，页面在内存与外存之间频繁调度，以至于调度页面所需时间比进程实际运行的时间还多，此时系统效率急剧下降，甚至导致系统崩溃。这种现象称为颠簸或抖动（thrashing） 。

抖动的后果：缺页率急剧增加，内存有效存取时间加长，系统吞吐量骤减（趋近于零） ；系统已基本不能完成什么任务。

抖动产生原因：同时运行的进程数过多，进程频繁访问的页面数高于可用的物理块数，造成进程运行时频繁缺页。CPU 利用率太低时，调度程序就会增加多道程序度，将新进程引入系统中，反而进一步导致处理机利用率的下降。


- [分段，分页与段页式存储管理](https://blog.csdn.net/zephyr_be_brave/article/details/8944967)

### 5.2 页面置换算法
在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生 **缺页中断**。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

### 5.3 缺页中断
页缺失指的是当软件试图访问已映射在虚拟地址空间中，但是目前并未被加载在物理内存中的一个分页时，由中央处理器的内存管理单元所发出的中断。  
通常情况下，用于处理此中断的程序是操作系统的一部分。如果操作系统判断此次访问是有效的，那么操作系统会尝试将相关的分页从硬盘上的虚拟内存文件中调入内存。而如果访问是不被允许的，那么操作系统通常会结束相关的进程。

### 5.4 常见的置换算法

1. 先进先出置换算法（FIFO）  

> 最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即先进入内存的页，先退出内存。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。

2. 最近最久未使用（LRU）算法

> 它的实质是，当需要置换一页时，选择在之前一段时间里最久没有使用过的页面予以置换。  
> 其问题是怎么确定最后使用时间的顺序，对此有两种可行的办法：
> 1. 计数器。最简单的情况是使每个页表项对应一个使用时间字段，并给CPU增加一个逻辑时钟或计数器。每次存储访问，该时钟都加1。每当访问一个页面时，时钟寄存器的内容就被复制到相应页表项的使用时间字段中。这样我们就可以始终保留着每个页面最后访问的“时间”。在置换页面时，选择该时间值最小的页面。这样做， [1]  不仅要查页表，而且当页表改变时（因CPU调度）要 [1]  维护这个页表中的时间，还要考虑到时钟值溢出的问题。
> 2. 栈。用一个栈保留页号。每当访问一个页面时，就把它从栈中取出放在栈顶上。这样一来，栈顶总是放有目前使用最多的页，而栈底放着目前最少使用的页。由于要从栈的中间移走一项，所以要用具有头尾指针的双向链连起来。在最坏的情况下，移走一页并把它放在栈顶上需要改动6个指针。每次修改都要有开销，但需要置换哪个页面却可直接得到，用不着查找，因为尾指针指向栈底，其中有被置换页。


## 6. IO多路复用
### 6.0 IO五种模型（阻塞IO、非阻塞IO、多路复用IO、信号驱动IO、异步IO）
同步就是当一个进程发起一个函数（任务）调用的时候，一直等待直到函数（任务）完成，而进程继续处于激活状态。而异步情况下是当一个进程发起一个函数（任务）调用的时候，不会等函数返回，而是继续往下执行当，函数返回的时候通过状态、通知、事件等方式通知进程任务完成。

阻塞是当请求不能满足的时候就将进程挂起，而非阻塞则不会阻塞当前进程，即阻塞与非阻塞针对的是进程或线程而同步与异步所针对的是功能函数。

IO复用：为了解释这个名词，首先来理解下复用这个概念，复用也就是共用的意思，这样理解还是有些抽象，为此，咱们来理解下复用在通信领域的使用，在通信领域中为了充分利用网络连接的物理介质，往往在同一条网络链路上采用时分复用或频分复用的技术使其在同一链路上传输多路信号，到这里我们就基本上理解了复用的含义，即公用某个“介质”来尽可能多的做同一类(性质)的事，那IO复用的“介质”是什么呢？为此我们首先来看看服务器编程的模型，客户端发来的请求服务端会产生一个进程来对其进行服务，每当来一个客户请求就产生一个进程来服务，然而进程不可能无限制的产生，因此为了解决大量客户端访问的问题，引入了IO复用技术，即：一个进程可以同时对多个客户请求进行服务。

> **同步** ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）；  
> **异步** ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）；  
> **阻塞** ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）；  
> **非阻塞** ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成）

[IO五种模型（阻塞IO、非阻塞IO、多路复用IO、信号驱动IO、异步IO）](https://blog.csdn.net/skiof007/article/details/52873421):

------

> `select`，`poll`，`epoll`都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

### 6.1 前言：系统层面概念说明
在进行解释之前，首先要说明几个概念：
- 用户空间和内核空间
- 进程切换
- 进程的阻塞
- 文件描述符
- 缓存 I/O

#### 6.1.1 用户空间与内核空间
现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），**保证内核的安全**，操心系统将虚拟空间划分为两部分，**一部分为内核空间，一部分为用户空间**。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。
#### 6.1.2 进程切换
为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：
1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新PCB信息。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

注：总而言之就是很耗资源。
#### 6.1.3 进程的阻塞
正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。

**当进程进入阻塞状态，是不占用CPU资源的。**
#### 6.1.4 文件描述符
文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

**文件描述符在形式上是一个非负整数。**实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。
#### 6.1.5 缓存 I/O
缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

- 缓存 I/O 的缺点：
数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。
-------------
### 6.2 I/O 多路复用
I/O 多路复用(IO multiplexing)就是我们说的`select`，`poll`，`epoll`，有些地方也称这种IO方式为事件驱动(event driven IO)。`select/epoll`的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是`select`，`poll`，`epoll`这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

> 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。

所以，如果处理的连接数不是很高的话，使用`select/epoll`的web server不一定比使用多线程multi-threading + 阻塞blocking IO的web server性能更好，可能延迟还更大。`select/epoll`的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

在IO多路复用中，实际中，对于每一个socket，一般都设置成为非阻塞non-blocking，但是，整个用户的process其实是一直被阻塞block的。只不过process是被`select`这个函数block，而不是被socket IO给block。
### 6.3 select、poll、epoll详解
#### 6.3.1 select
select的工作流程：
单个进程就可以同时处理多个网络连接的io请求（同时阻塞多个io操作）。基本原理就是程序呼叫select，然后整个程序就阻塞了，这时候，select会将需要监控的readfds集合拷贝到内核空间（假设监控的仅仅是socket可读），kernel就会轮询检查所有select负责的fd，当找到一个client中的数据准备好了，select就会返回，这个时候程序就会系统调用，将数据从kernel复制到进程缓冲区。

通过上面的select逻辑过程分析，相信大家都意识到，select存在两个问题：
1. 被监控的fds需要从用户空间拷贝到内核空间。为了减少数据拷贝带来的性能损坏，内核对被监控的fds集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)。
2. 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次调用sk的poll函数收集可读事件。由于当初的需求是朴素，仅仅关心是否有数据可读这样一个事件，当事件通知来的时候，由于数据的到来是异步的，我们不知道事件来的时候，有多少个被监控的socket有数据可读了，于是，只能挨个遍历每个socket来收集可读事件。

#### 6.3.2 Poll
poll的原理与select非常相似，差别如下：

- 描述fd集合的方式不同，poll使用 pollfd 结构而不是select结构fd_set结构，所以poll是链式的，没有最大连接数的限制
- poll有一个特点是水平触发，也就是通知程序fd就绪后，这次没有被处理，那么下次poll的时候会再次通知同个fd已经就绪。

poll机制虽然改进了select的监控大小1024的限制，但以下两个性能问题还没有解决。略显鸡肋。
1. fds集合需要从用户空间拷贝到内核空间的问题，我们希望不需要拷贝
2. 当被监控的fds中某些有数据可读的时候，我们希望通知更加精细一点，就是我们希望能够从通知中得到有可读事件的fds列表，而不是需要遍历整个fds来收集。
#### 6.3.3 epoll 解决问题
假设现实中，有1百万个客户端同时与一个服务器保持着tcp连接，而每一个时刻，通常只有几百上千个tcp连接是活跃的，这时候我们仍然使用select/poll机制，kernel必须在搜寻完100万个fd之后，才能找到其中状态是active的，这样资源消耗大而且效率低下。

#### (a) fds集合拷贝问题的解决
对于IO多路复用，有两件事是必须要做的(对于监控可读事件而言)：1. 准备好需要监控的fds集合；2. 探测并返回fds集合中哪些fd可读了。细看select或poll的函数原型，我们会发现，每次调用select或poll都在重复地准备(集中处理)整个需要监控的fds集合。然而对于频繁调用的select或poll而言，fds集合的变化频率要低得多，我们没必要每次都重新准备(集中处理)整个fds集合。

于是，`epoll`引入了`epoll_ctl`系统调用，将高频调用的`epoll_wait`和低频的`epoll_ctl`隔离开。同时，`epoll_ctl`通过(`EPOLL_CTL_ADD`、`EPOLL_CTL_MOD`、`EPOLL_CTL_DEL`)三个操作来分散对需要监控的fds集合的修改，做到了有变化才变更，将`select/poll`高频、大块内存拷贝(集中处理)变成`epoll_ctl`的低频、小块内存的拷贝(分散处理)，避免了大量的内存拷贝。

#### (b) 按需遍历就绪的fds集合
为了做到只遍历就绪的fd，我们需要有个地方来组织那些已经就绪的fd。为此，epoll引入了一个中间层，一个双向链表(ready_list)，一个单独的睡眠队列(single_epoll_wait_list)，并且，与select或poll不同的是，epoll的process不需要同时插入到多路复用的socket集合的所有睡眠队列中，相反process只是插入到中间层的epoll的单独睡眠队列中，process睡眠在epoll的单独队列上，等待事件的发生。

#### 6.3.4 小结
- select, poll是为了解決同时大量IO的情況（尤其网络服务器），但是随着连接数越多，性能越差
- epoll是select和poll的改进方案，在 linux 上可以取代 select 和 poll，可以处理大量连接的性能问题

-----
- [Linux IO模式及 select、poll、epoll详解](https://segmentfault.com/a/1190000003063859)
- [细谈Select,Poll,Epoll](https://juejin.im/post/5a3b7c1a5188252582278ef2)
- [大话 Select、Poll、Epoll](https://cloud.tencent.com/developer/article/1005481)
-----
## 7. 文件系统
### 7.1 Linux的EXT2文件系统
- 这部分就是inode牵扯到的相关知识
- 对于一个磁盘分区来说，在被指定为相应的文件系统后，整个分区被分为 1024，2048 和 4096 字节大小的块。根据块使用的不同，可分为：

- **超级块**(Superblock): 这是整个文件系统的第一块空间。包括整个文件系统的基本信息，如块大小，inode/block的总量、使用量、剩余量，指向空间 inode 和数据块的指针等相关信息。  
- **inode块**(文件索引节点) : 文件系统索引,记录文件的属性。它是文件系统的最基本单元，是文件系统连接任何子目录、任何文件的桥梁。每个子目录和文件只有唯一的一个 inode 块。它包含了文件系统中文件的基本属性(文件的长度、创建及修改时间、权限、所属关系)、存放数据的位置等相关信息. 在 Linux 下可以通过 "ls -li" 命令查看文件的 inode 信息。硬连接和源文件具有相同的 inode 。  
- **数据块**(Block) :实际记录文件的内容，若文件太大时，会占用多个 block。为了提高目录访问效率，Linux 还提供了表达路径与 inode 对应关系的 dentry 结构。它描述了路径信息并连接到节点 inode，它包括各种目录信息，还指向了 inode 和超级块。  
    
就像一本书有封面、目录和正文一样。在文件系统中，超级块就相当于封面，从封面可以得知这本书的基本信息； inode 块相当于目录，从目录可以得知各章节内容的位置；而数据块则相当于书的正文，记录着具体内容。

- [磁盘 I/O 那些事：从硬件到Linux文件系统](https://tech.meituan.com/about_desk_io.html)  
从硬盘构造，到Linux文件系统的优化，再到其他开源系统（HDFS、Kafka）基于磁盘IO的设计


### 7.2 Inode是什么
- 文件储存在硬盘上，硬盘的最小存储单位叫做"扇区"（Sector）。每个扇区储存512字节（相当于0.5KB）。  
操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个"块"（block）。这种由多个扇区组成的"块"，是文件存取的最小单位。"块"的大小，最常见的是4KB，即连续八个 sector组成一个 block。  
文件数据都储存在"块"中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为"索引节点"。  
每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。
- [链接](http://www.ruanyifeng.com/blog/2011/12/inode.html)
